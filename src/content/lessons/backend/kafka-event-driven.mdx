---
title: "Kafka e Event-Driven Architecture"
description: "Event-driven architecture, Kafka internals (topics, partitions, log compaction), producers, consumers, exactly-once semantics, Event Sourcing, CQRS, Outbox pattern e comparaÃ§Ã£o com RabbitMQ/SQS/NATS"
track: "backend"
order: 24
section: "ComunicaÃ§Ã£o"
priority: "high"
tags: ["kafka", "event-driven", "event-sourcing", "CQRS", "streaming", "mensageria", "outbox-pattern", "CDC"]
prerequisites: ["message-queues", "arquitetura-backend"]
keyTakeaways:
  - "Kafka Ã© um distributed commit log: mensagens sÃ£o append-only, imutÃ¡veis e retidas por tempo configurÃ¡vel â€” fundamentalmente diferente de message queues tradicionais"
  - "Exactly-once semantics em Kafka requer idempotent producer (enable.idempotence=true) + transactional API + read_committed isolation no consumer"
  - "Event Sourcing armazena o histÃ³rico completo de mudanÃ§as como eventos imutÃ¡veis; CQRS separa modelos de leitura e escrita para otimizar cada um independentemente"
  - "O Outbox pattern resolve o problema de dual-write (banco + mensageria) usando CDC (Debezium) para capturar mudanÃ§as do banco e publicar como eventos"
---

## Event-Driven Architecture

### Eventos vs Comandos vs Queries

Antes de qualquer coisa, Ã© preciso distinguir trÃªs conceitos que frequentemente sÃ£o confundidos. Essa distinÃ§Ã£o nÃ£o Ã© acadÃªmica â€” ela determina como vocÃª modela a comunicaÃ§Ã£o entre serviÃ§os.

```
EVENTO                          COMANDO                         QUERY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"Algo aconteceu"                "FaÃ§a algo"                     "Me diga algo"
Passado (imutÃ¡vel)              Imperativo (pode ser rejeitado) Interrogativo (sem side effects)
OrderPlaced                     PlaceOrder                      GetOrderById
Broadcast (0..N consumers)      EndereÃ§ado (1 handler)          EndereÃ§ado (1 handler)
Publisher nÃ£o sabe quem consome Handler pode rejeitar            Handler retorna dados
Sem expectativa de resposta     Espera confirmaÃ§Ã£o ou erro       Espera resposta com dados

Exemplo concreto:
  Comando:  PlaceOrder { userId: "u1", items: [...], total: 250.00 }
  Evento:   OrderPlaced { orderId: "o1", userId: "u1", total: 250.00, at: "2025-01-15T10:30:00Z" }
  Query:    GetOrder { orderId: "o1" } â†’ { orderId: "o1", status: "placed", ... }
```

Um **evento** Ã© um fato imutÃ¡vel sobre algo que jÃ¡ aconteceu. Um **comando** Ã© uma intenÃ§Ã£o que pode ser aceita ou rejeitada. Uma **query** Ã© uma leitura sem side effects. Essa trÃ­ade Ã© a base de CQRS e Event Sourcing.

---

### Tipos de Event-Driven Architecture

Martin Fowler descreve trÃªs padrÃµes distintos de uso de eventos. Cada um tem trade-offs diferentes.

```
1. EVENT NOTIFICATION
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Evento carrega MÃNIMO de dados â€” apenas o que mudou e um ID.
   O consumer precisa chamar o producer de volta para obter detalhes.

   OrderService â”€â”€â–º { event: "OrderPlaced", orderId: "o1" } â”€â”€â–º ShippingService
                                                                      â”‚
                   â—„â”€â”€ GET /orders/o1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   âœ“ Acoplamento mÃ­nimo no payload
   âœ— Acoplamento temporal: consumer depende do producer estar online
   âœ— Mais latÃªncia (ida + volta)


2. EVENT-CARRIED STATE TRANSFER
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Evento carrega TODOS os dados necessÃ¡rios. Consumer nÃ£o precisa
   chamar ninguÃ©m de volta â€” Ã© autossuficiente.

   OrderService â”€â”€â–º { event: "OrderPlaced", orderId: "o1",
                       userId: "u1", items: [...], total: 250.00,
                       shippingAddress: {...} } â”€â”€â–º ShippingService

   âœ“ Consumer totalmente desacoplado (temporal e espacialmente)
   âœ“ Menor latÃªncia (sem round-trip)
   âœ— Payload grande, possÃ­vel duplicaÃ§Ã£o de dados
   âœ— Consumer pode ficar com dados stale


3. EVENT SOURCING
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Eventos sÃ£o a FONTE PRIMÃRIA de verdade. Estado Ã© derivado
   fazendo replay de todos os eventos.

   [OrderCreated] â†’ [ItemAdded] â†’ [ItemAdded] â†’ [OrderPaid] â†’ [OrderShipped]
        â”‚               â”‚              â”‚              â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              Estado atual = f(eventos)

   âœ“ Auditoria completa, time-travel debugging, replay
   âœ— Complexidade significativa, event versioning, eventual consistency
```

---

### Arquitetura Event-Driven vs Request-Response

```
REQUEST-RESPONSE (sÃ­ncrono)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Client  â”‚â”€â”€â”€â”€â–ºâ”‚  Order   â”‚â”€â”€â”€â”€â–ºâ”‚ Payment  â”‚â”€â”€â”€â”€â–ºâ”‚ Shipping â”‚
  â”‚          â”‚â—„â”€â”€â”€â”€â”‚ Service  â”‚â—„â”€â”€â”€â”€â”‚ Service  â”‚â—„â”€â”€â”€â”€â”‚ Service  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚Inventory â”‚
                         â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â€¢ LatÃªncia = soma de todas as chamadas (serial)
  â€¢ Uma falha propaga em cascata
  â€¢ Forte acoplamento temporal


EVENT-DRIVEN (assÃ­ncrono)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Client  â”‚â”€â”€â”€â”€â–ºâ”‚  Order   â”‚â”€â”€publishâ”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚          â”‚â—„â”€â”€â”€â”€â”‚ Service  â”‚            â”‚                     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   Event Backbone    â”‚
                   (202 Accepted)          â”‚   (Kafka / NATS)    â”‚
                                           â”‚                     â”‚
                                           â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                                              â”‚      â”‚      â”‚
                                              â–¼      â–¼      â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚Payment â”‚ â”‚Inv.â”‚ â”‚Shipping â”‚
                                        â”‚Worker  â”‚ â”‚Wkr â”‚ â”‚Worker   â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â€¢ LatÃªncia do client = apenas o tempo do Order Service
  â€¢ Cada worker escala independentemente
  â€¢ Falha de um nÃ£o afeta os outros
  â€¢ Trade-off: eventual consistency, complexidade operacional
```

**Vantagens**: loose coupling, temporal decoupling, scalability horizontal independente por consumer, absorÃ§Ã£o natural de picos (backpressure via partitions/queues), auditoria nativa se eventos sÃ£o persistidos.

**Desvantagens**: eventual consistency (read-your-own-writes Ã© difÃ­cil), debugging distribuÃ­do Ã© complexo (precisa de correlation IDs + distributed tracing), ordem de eventos pode ser desafiadora, infraestrutura de mensageria Ã© mais um componente crÃ­tico para operar.

---

## Kafka Internals

### Arquitetura: Brokers, Topics, Partitions, Segments

Kafka nÃ£o Ã© uma message queue. Ã‰ um **distributed commit log** â€” um log append-only, durÃ¡vel, particionado e replicado. Essa distinÃ§Ã£o Ã© fundamental.

```
KAFKA CLUSTER â€” TOPOLOGIA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                        KAFKA CLUSTER                            â”‚
  â”‚                                                                 â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
  â”‚  â”‚   Broker 0    â”‚  â”‚   Broker 1    â”‚  â”‚   Broker 2    â”‚       â”‚
  â”‚  â”‚               â”‚  â”‚               â”‚  â”‚               â”‚       â”‚
  â”‚  â”‚  orders-p0 (L)â”‚  â”‚  orders-p0 (F)â”‚  â”‚  orders-p0 (F)â”‚       â”‚
  â”‚  â”‚  orders-p1 (F)â”‚  â”‚  orders-p1 (L)â”‚  â”‚  orders-p1 (F)â”‚       â”‚
  â”‚  â”‚  orders-p2 (F)â”‚  â”‚  orders-p2 (F)â”‚  â”‚  orders-p2 (L)â”‚       â”‚
  â”‚  â”‚               â”‚  â”‚               â”‚  â”‚               â”‚       â”‚
  â”‚  â”‚  payments-p0(L)â”‚  â”‚  payments-p1(L)â”‚  â”‚               â”‚       â”‚
  â”‚  â”‚  payments-p1(F)â”‚  â”‚  payments-p0(F)â”‚  â”‚               â”‚       â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
  â”‚                                                                 â”‚
  â”‚  (L) = Leader    (F) = Follower                                 â”‚
  â”‚  Cada partition tem exatamente 1 leader e N-1 followers         â”‚
  â”‚  Reads e writes vÃ£o APENAS para o leader (por padrÃ£o)           â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Producers â”€â”€â–º Leaders (writes)
  Consumers â”€â”€â–º Leaders (reads) â€” ou followers com rack-aware fetch (KIP-392)
```

**Broker**: um processo Kafka rodando em uma mÃ¡quina. Um cluster tem N brokers. Cada broker armazena um subconjunto das partitions.

**Topic**: categoria lÃ³gica de eventos (ex: `orders`, `payments`, `user-events`). Ã‰ apenas um nome â€” os dados vivem nas partitions.

**Partition**: unidade fundamental de paralelismo. Ã‰ um log append-only, ordenado, imutÃ¡vel. Cada mensagem dentro de uma partition tem um **offset** sequencial monotonicamente crescente.

---

### Partitions e Offsets

```
TOPIC "orders" â€” 3 PARTITIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Partition 0:  [0] [1] [2] [3] [4] [5] [6] [7] â”€â”€â–º writes (append-only)
                 â”‚                           â”‚
                 oldest                      newest (high watermark)

  Partition 1:  [0] [1] [2] [3] [4] [5] â”€â”€â–º writes
                                   â–²
                                   â”‚
                            consumer offset (grupo "payment-service")

  Partition 2:  [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] â”€â”€â–º writes


  CONSUMER GROUPS
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Group "payment-service":
    Consumer A â†â”€â”€ Partition 0, Partition 1
    Consumer B â†â”€â”€ Partition 2

  Group "analytics-service":
    Consumer C â†â”€â”€ Partition 0
    Consumer D â†â”€â”€ Partition 1
    Consumer E â†â”€â”€ Partition 2

  â€¢ Cada partition Ã© consumida por EXATAMENTE 1 consumer dentro de um grupo
  â€¢ Consumers > Partitions = consumers ociosos (nunca escale alÃ©m do nÂº de partitions)
  â€¢ Grupos diferentes sÃ£o independentes â€” cada um mantÃ©m seus prÃ³prios offsets
```

Cada consumer group rastreia seu progresso por partition via **offsets** armazenados no topic interno `__consumer_offsets`. Isso permite que cada grupo leia no seu prÃ³prio ritmo, e permite **replay** â€” basta resetar o offset para o inÃ­cio.

---

### Segments: Como Dados SÃ£o Armazenados em Disco

Uma partition nÃ£o Ã© um Ãºnico arquivo. Ela Ã© dividida em **segments** â€” arquivos fÃ­sicos no disco.

```
PARTITION 0 NO DISCO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /var/kafka-logs/orders-0/
  â”œâ”€â”€ 00000000000000000000.log      â† segment file (offsets 0-999)
  â”œâ”€â”€ 00000000000000000000.index    â† sparse index (offset â†’ posiÃ§Ã£o no .log)
  â”œâ”€â”€ 00000000000000000000.timeindex â† timestamp index
  â”œâ”€â”€ 00000000000000001000.log      â† segment file (offsets 1000-1999)
  â”œâ”€â”€ 00000000000000001000.index
  â”œâ”€â”€ 00000000000000001000.timeindex
  â””â”€â”€ 00000000000000002000.log      â† ACTIVE segment (writes aqui)

  â€¢ segment.bytes (default 1GB): tamanho mÃ¡ximo de cada segment
  â€¢ O segment ativo recebe writes. Quando atinge o limite, fecha e um novo abre.
  â€¢ Segments antigos sÃ£o deletados por retention policy (time ou size)
  â€¢ Index Ã© sparse: aponta para cada N-Ã©simo offset (nÃ£o para todos)
    â†’ Para encontrar offset 1050: busca no index o entry mais prÃ³ximo â‰¤ 1050,
      depois faz sequential scan no .log a partir dali
```

---

### Log Compaction

Diferente de retenÃ§Ã£o por tempo, **log compaction** retÃ©m apenas o **Ãºltimo valor por key**. Ideal para changelogs e snapshots de estado.

```
LOG COMPACTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  ANTES (log cru):
  offset  key       value
  0       user-1    { name: "Alice", email: "a@x.com" }
  1       user-2    { name: "Bob", email: "b@x.com" }
  2       user-1    { name: "Alice", email: "alice@new.com" }   â† atualizaÃ§Ã£o
  3       user-3    { name: "Charlie", email: "c@x.com" }
  4       user-2    null                                         â† tombstone (delete)
  5       user-1    { name: "Alice Z.", email: "alice@new.com" } â† atualizaÃ§Ã£o

  DEPOIS (compactado):
  offset  key       value
  3       user-3    { name: "Charlie", email: "c@x.com" }
  4       user-2    null                                         â† tombstone retido temporariamente
  5       user-1    { name: "Alice Z.", email: "alice@new.com" }

  â€¢ Apenas o ÃšLTIMO valor por key sobrevive
  â€¢ Tombstones (value=null) sÃ£o retidos por delete.retention.ms, depois removidos
  â€¢ Ideal para: __consumer_offsets, KTable changelogs, CDC snapshots
  â€¢ cleanup.policy=compact (ou compact,delete para combinar ambos)
```

---

### Replication: Leader, Followers e ISR

```
REPLICAÃ‡ÃƒO â€” PARTITION "orders-0" COM replication.factor=3
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Broker 0   â”‚     â”‚   Broker 1   â”‚     â”‚   Broker 2   â”‚
  â”‚              â”‚     â”‚              â”‚     â”‚              â”‚
  â”‚  orders-0   â”‚     â”‚  orders-0   â”‚     â”‚  orders-0   â”‚
  â”‚  [LEADER]   â”‚â”€â”€â”€â”€â–ºâ”‚  [FOLLOWER] â”‚     â”‚  [FOLLOWER] â”‚
  â”‚             â”‚     â”‚  (ISR)      â”‚     â”‚  (ISR)      â”‚
  â”‚  offset: 50 â”‚     â”‚  offset: 50 â”‚     â”‚  offset: 48 â”‚ â† lag!
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                    â–²                    â–²
         â”‚                    â”‚                    â”‚
      writes              fetch from            fetch from
      + reads              leader               leader

  ISR (In-Sync Replicas) = { Broker 0, Broker 1 }
  Broker 2 caiu do ISR (lag > replica.lag.time.max.ms = 30s)

  min.insync.replicas=2:
    Se ISR < 2, o leader RECUSA writes (NotEnoughReplicasException)
    Garante que pelo menos 2 cÃ³pias existem antes de ACK

  Se o Leader cai:
    Novo leader eleito APENAS entre ISR members
    unclean.leader.election.enable=false (default) â†’ sem eleiÃ§Ã£o de follower out-of-sync
    unclean.leader.election.enable=true â†’ aceita perda de dados para priorizar disponibilidade
```

A combinaÃ§Ã£o recomendada para durabilidade em produÃ§Ã£o: `replication.factor=3`, `min.insync.replicas=2`, `acks=all` no producer. Isso garante que toda mensagem escrita Ã© confirmada por pelo menos 2 rÃ©plicas antes do ACK.

---

### KRaft: Sem ZooKeeper

A partir do Kafka 3.3+, o **KRaft mode** (Kafka Raft) substitui o ZooKeeper para metadata management. O controller Ã© agora um quorum interno de brokers.

```
KRAFT MODE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  ANTES (com ZooKeeper):                DEPOIS (KRaft):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ZooKeeperâ”‚â—„â”€â”€â”€â–ºâ”‚  Broker  â”‚        â”‚  Broker (Controller) â”‚
  â”‚ Ensemble â”‚     â”‚          â”‚        â”‚  Quorum via Raft     â”‚
  â”‚ (3 nodes)â”‚     â”‚          â”‚        â”‚                      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â€¢ Metadata agora armazenado em um topic interno: __cluster_metadata
  â€¢ Controller quorum: 3 brokers votam (Raft consensus)
  â€¢ Vantagem: menos componentes, startup mais rÃ¡pido, sem split-brain do ZK
  â€¢ ZooKeeper mode deprecated desde Kafka 3.5, removido no 4.0
```

---

## Producer

### Anatomia de uma Mensagem Kafka

```
KAFKA RECORD (ProducerRecord)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Key (opcional)    â”‚  Value              â”‚  Headers   â”‚
  â”‚  bytes[]           â”‚  bytes[]            â”‚  key-value â”‚
  â”‚  ex: "order-123"   â”‚  ex: JSON payload   â”‚  metadata  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  Topic: "orders"                                      â”‚
  â”‚  Partition: determinado pela key (ou round-robin)     â”‚
  â”‚  Timestamp: create time ou log append time            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Key determina a partition:
    hash(key) % numPartitions â†’ partition number
    Mesma key â†’ sempre mesma partition â†’ ordenaÃ§Ã£o garantida por key
    Key null â†’ round-robin entre partitions
```

---

### Partitioning Strategy

```
ESTRATÃ‰GIAS DE PARTICIONAMENTO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  KEY-BASED (default):
    hash(key) % numPartitions
    âœ“ Garante ordenaÃ§Ã£o por key (ex: todos os eventos de um orderId na mesma partition)
    âœ— Hot partition se keys nÃ£o sÃ£o uniformemente distribuÃ­das

  ROUND-ROBIN (key = null):
    Distribui uniformemente entre partitions
    âœ“ MÃ¡ximo throughput, distribuiÃ§Ã£o uniforme
    âœ— Sem garantia de ordenaÃ§Ã£o

  CUSTOM PARTITIONER:
    Implementa lÃ³gica customizada (ex: por regiÃ£o geogrÃ¡fica, por tenant)
    âœ“ Controle total
    âœ— Complexidade extra, risco de skew
```

---

### ACKs Configuration

```
acks=0    FIRE AND FORGET
          Producer envia e nÃ£o espera confirmaÃ§Ã£o.
          MÃ¡ximo throughput. Perda de mensagens aceita.
          Use case: mÃ©tricas, logs nÃ£o crÃ­ticos.

acks=1    LEADER ACKNOWLEDGED
          Producer espera ACK do leader.
          Se leader cai ANTES de replicar â†’ mensagem perdida.
          Bom equilÃ­brio throughput/durabilidade para maioria dos casos.

acks=all  ALL ISR ACKNOWLEDGED (acks=-1)
          Producer espera ACK de TODOS os ISR.
          Combinado com min.insync.replicas=2 â†’ mÃ¡xima durabilidade.
          Mais latÃªncia, menos throughput.
          Use case: transaÃ§Ãµes financeiras, eventos crÃ­ticos.
```

---

### Idempotent Producer

Sem idempotÃªncia, retries podem causar mensagens duplicadas. O idempotent producer resolve isso com **producer ID** e **sequence numbers**.

```
IDEMPOTENT PRODUCER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  SEM idempotÃªncia:
  Producer â”€â”€â–º msg(seq=1) â”€â”€â–º Broker (write OK)
  Producer â”€â”€â–º msg(seq=1) â”€â”€â–º Broker (timeout, mas write OK)
  Producer â”€â”€â–º msg(seq=1) â”€â”€â–º Broker (retry â†’ DUPLICATA!)

  COM idempotÃªncia (enable.idempotence=true):
  Producer(PID=42) â”€â”€â–º msg(seq=1) â”€â”€â–º Broker (write OK, registra PID+seq)
  Producer(PID=42) â”€â”€â–º msg(seq=1) â”€â”€â–º Broker (retry â†’ detecta duplicata â†’ ignora, retorna ACK)

  O Broker mantÃ©m: { PID: 42, partition: 0, lastSeq: 1 }
  Se recebe seq â‰¤ lastSeq â†’ duplicata â†’ ignora
  Se recebe seq > lastSeq + 1 â†’ out of order â†’ rejeita (OutOfOrderSequenceException)
```

---

### Producer: CÃ³digo TypeScript com KafkaJS

```typescript
// producer.ts â€” Kafka producer com KafkaJS
import { Kafka, CompressionTypes, logLevel } from 'kafkajs';

const kafka = new Kafka({
  clientId: 'order-service',
  brokers: ['kafka-1:9092', 'kafka-2:9092', 'kafka-3:9092'],
  logLevel: logLevel.WARN,
  retry: {
    initialRetryTime: 100,     // ms antes do primeiro retry
    retries: 8,                // nÃºmero mÃ¡ximo de retries
    maxRetryTime: 30000,       // mÃ¡ximo backoff entre retries
    factor: 2,                 // multiplicador exponencial
  },
});

const producer = kafka.producer({
  allowAutoTopicCreation: false,        // nunca criar topics automaticamente em produÃ§Ã£o
  idempotent: true,                      // enable.idempotence â€” elimina duplicatas
  maxInFlightRequests: 5,                // com idempotÃªncia, atÃ© 5 Ã© seguro (ordering mantido)
  transactionalId: 'order-tx-producer',  // necessÃ¡rio para transaÃ§Ãµes
});

interface OrderEvent {
  orderId: string;
  userId: string;
  items: Array<{ productId: string; quantity: number; price: number }>;
  total: number;
  occurredAt: string;
}

async function publishOrderPlaced(event: OrderEvent): Promise<void> {
  await producer.connect();

  // Mensagem com key = orderId â†’ garante que todos os eventos do mesmo
  // pedido vÃ£o para a mesma partition â†’ ordenaÃ§Ã£o por pedido
  const result = await producer.send({
    topic: 'orders',
    compression: CompressionTypes.LZ4,   // LZ4: melhor trade-off velocidade/compressÃ£o
    acks: -1,                             // acks=all
    timeout: 30000,                       // timeout em ms
    messages: [
      {
        key: event.orderId,               // partition key
        value: JSON.stringify(event),
        headers: {
          'event-type': 'OrderPlaced',
          'schema-version': '2',
          'correlation-id': crypto.randomUUID(),
          'source-service': 'order-service',
        },
        timestamp: Date.now().toString(),
      },
    ],
  });

  // result: [{ topicName, partition, errorCode, baseOffset, logAppendTime, logStartOffset }]
  console.log(`Published to partition ${result[0].partition}, offset ${result[0].baseOffset}`);
}

// â”€â”€â”€ TRANSACTIONAL PRODUCER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Escreve em mÃºltiplos topics atomicamente (tudo ou nada)
async function placeOrderTransaction(
  orderEvent: OrderEvent,
  inventoryReservation: { productId: string; quantity: number }
): Promise<void> {
  const transaction = await producer.transaction();

  try {
    await transaction.send({
      topic: 'orders',
      messages: [{ key: orderEvent.orderId, value: JSON.stringify(orderEvent) }],
    });

    await transaction.send({
      topic: 'inventory-reservations',
      messages: [{
        key: inventoryReservation.productId,
        value: JSON.stringify(inventoryReservation),
      }],
    });

    // Commit: ambas as mensagens ficam visÃ­veis atomicamente
    await transaction.commit();
  } catch (error) {
    // Abort: nenhuma mensagem fica visÃ­vel
    await transaction.abort();
    throw error;
  }
}
```

---

## Consumer

### Consumer Groups e Rebalancing

Quando um consumer entra ou sai de um grupo, ou quando partitions sÃ£o adicionadas, ocorre um **rebalance** â€” redistribuiÃ§Ã£o de partitions entre consumers.

```
REBALANCING PROTOCOLS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  EAGER REBALANCE (legado):
    1. TODOS os consumers param de consumir
    2. TODOS revogam TODAS as partitions
    3. Coordinator redistribui
    4. Todos recomeÃ§am

    âœ— Stop-the-world: downtime total durante rebalance
    âœ— Pode levar segundos em clusters grandes


  COOPERATIVE-STICKY REBALANCE (padrÃ£o moderno):
    1. Coordinator calcula o diff (quais partitions precisam mover)
    2. APENAS as partitions afetadas sÃ£o revogadas
    3. Consumers que mantÃªm suas partitions NÃƒO param

    âœ“ Incremental: maioria dos consumers nÃ£o Ã© afetada
    âœ“ Muito mais rÃ¡pido e menos disruptivo

  partition.assignment.strategy=CooperativeStickyAssignor
```

---

### Offset Management

```
AUTO-COMMIT (enable.auto.commit=true, auto.commit.interval.ms=5000)
  Consumer commita offsets automaticamente a cada 5s.
  Se crashar entre auto-commits â†’ reprocessa mensagens â†’ AT-LEAST-ONCE.
  Se processar e commitar antes de completar â†’ perde mensagens â†’ AT-MOST-ONCE.
  âš  NÃ£o recomendado para processamento crÃ­tico.


MANUAL COMMIT â€” DUAS VARIANTES:
  commitSync():  Bloqueia atÃ© o broker confirmar o commit.
                 Mais lento, mas garante que offset estÃ¡ salvo.

  commitAsync(): Non-blocking. Callback para sucesso/falha.
                 Mais rÃ¡pido, mas retry em caso de falha Ã© perigoso
                 (pode commitar offset antigo DEPOIS de um mais recente).

  PadrÃ£o recomendado: commitAsync() no loop normal, commitSync() no shutdown.
```

---

### Delivery Semantics

```
AT-MOST-ONCE:
  Commit offset ANTES de processar.
  Se crashar durante processamento â†’ mensagem perdida.
  Use case: dados descartÃ¡veis.

AT-LEAST-ONCE:
  Processa ANTES de commitar offset.
  Se crashar depois de processar mas antes de commitar â†’ reprocessa.
  Requer IDEMPOTÃŠNCIA no consumer.
  Use case: maioria dos sistemas (com idempotent handler).

EXACTLY-ONCE (end-to-end):
  Requer TODOS os trÃªs:
    1. Idempotent producer (enable.idempotence=true)
    2. Transactional API (begin/commit/abort)
    3. Consumer com isolation.level=read_committed

  O consumer sÃ³ vÃª mensagens de transaÃ§Ãµes COMMITTED.
  Mensagens de transaÃ§Ãµes abortadas sÃ£o invisÃ­veis.

  âš  Exactly-once sÃ³ Ã© nativo dentro do ecossistema Kafka (Kafka â†’ Kafka).
  Para Kafka â†’ sistema externo, vocÃª PRECISA de idempotÃªncia no consumer.
```

---

### Consumer: CÃ³digo TypeScript com KafkaJS

```typescript
// consumer.ts â€” Kafka consumer com manual commit e error handling
import { Kafka, EachMessagePayload, logLevel } from 'kafkajs';

const kafka = new Kafka({
  clientId: 'payment-service',
  brokers: ['kafka-1:9092', 'kafka-2:9092', 'kafka-3:9092'],
  logLevel: logLevel.WARN,
});

const consumer = kafka.consumer({
  groupId: 'payment-service-group',
  sessionTimeout: 30000,           // tempo sem heartbeat antes de rebalance
  heartbeatInterval: 3000,         // intervalo de heartbeat (â‰¤ sessionTimeout / 3)
  maxWaitTimeInMs: 500,            // long-polling: espera atÃ© 500ms por novas mensagens
  maxBytesPerPartition: 1048576,   // 1MB max por partition por fetch
  retry: { retries: 5 },
});

// â”€â”€â”€ PROCESSAMENTO COM IDEMPOTÃŠNCIA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const processedEvents = new Set<string>(); // Em produÃ§Ã£o: Redis ou tabela no banco

async function handleOrderPlaced(payload: EachMessagePayload): Promise<void> {
  const { topic, partition, message, heartbeat } = payload;

  const eventId = message.headers?.['correlation-id']?.toString();
  if (!eventId) throw new Error('Missing correlation-id header');

  // IdempotÃªncia: verificar se jÃ¡ processou este evento
  if (processedEvents.has(eventId)) {
    console.log(`Duplicate event ${eventId}, skipping`);
    return;
  }

  const event = JSON.parse(message.value!.toString());

  // Processar pagamento
  await processPayment(event);

  // Marcar como processado (em produÃ§Ã£o: dentro da mesma transaÃ§Ã£o do banco)
  processedEvents.add(eventId);

  console.log(
    `Processed: topic=${topic}, partition=${partition}, ` +
    `offset=${message.offset}, key=${message.key?.toString()}`
  );

  // Heartbeat manual em processamentos longos (evita session timeout)
  await heartbeat();
}

// â”€â”€â”€ DEAD LETTER QUEUE (DLQ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const dlqProducer = kafka.producer();

async function sendToDLQ(
  originalMessage: EachMessagePayload,
  error: Error
): Promise<void> {
  await dlqProducer.send({
    topic: 'orders.dlq',
    messages: [{
      key: originalMessage.message.key,
      value: originalMessage.message.value,
      headers: {
        ...originalMessage.message.headers,
        'dlq-reason': error.message,
        'dlq-original-topic': originalMessage.topic,
        'dlq-original-partition': originalMessage.partition.toString(),
        'dlq-original-offset': originalMessage.message.offset,
        'dlq-timestamp': Date.now().toString(),
      },
    }],
  });
}

// â”€â”€â”€ RETRY COM BACKOFF + DLQ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function processWithRetry(
  payload: EachMessagePayload,
  maxRetries = 3
): Promise<void> {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      await handleOrderPlaced(payload);
      return; // sucesso
    } catch (error) {
      if (attempt === maxRetries) {
        console.error(`Failed after ${maxRetries} attempts, sending to DLQ`);
        await sendToDLQ(payload, error as Error);
        return; // nÃ£o relanÃ§a â€” mensagem vai para DLQ, consumer avanÃ§a
      }
      // Backoff exponencial: 1s, 2s, 4s
      const delay = Math.pow(2, attempt - 1) * 1000;
      await new Promise((resolve) => setTimeout(resolve, delay));
    }
  }
}

// â”€â”€â”€ INICIALIZAÃ‡ÃƒO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function startConsumer(): Promise<void> {
  await consumer.connect();
  await dlqProducer.connect();

  await consumer.subscribe({
    topics: ['orders'],
    fromBeginning: false, // comeÃ§a do Ãºltimo offset commitado (ou latest se novo grupo)
  });

  await consumer.run({
    autoCommit: false,               // manual commit!
    eachMessage: async (payload) => {
      await processWithRetry(payload);

      // Commit APÃ“S processamento bem-sucedido (ou envio para DLQ)
      await consumer.commitOffsets([{
        topic: payload.topic,
        partition: payload.partition,
        offset: (BigInt(payload.message.offset) + 1n).toString(),
      }]);
    },
  });
}

// Graceful shutdown
async function shutdown(): Promise<void> {
  await consumer.disconnect();
  await dlqProducer.disconnect();
}

process.on('SIGTERM', shutdown);
process.on('SIGINT', shutdown);
```

---

## Kafka Streams e Stream Processing

### KTable vs KStream

Kafka Streams opera sobre dois conceitos fundamentais: **KStream** (fluxo de eventos) e **KTable** (tabela materializada, changelog).

```
KStream â€” FLUXO DE EVENTOS (append-only)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Cada record Ã© um evento independente.
  Inserir "Alice comprou X" e depois "Alice comprou Y" = 2 eventos.

  key=alice, value=comprou-X    (t1)
  key=alice, value=comprou-Y    (t2)
  â†’ KStream vÃª: [comprou-X, comprou-Y] â€” ambos existem


KTable â€” TABELA MATERIALIZADA (changelog)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Cada record Ã© um upsert. Ãšltima value por key ganha.
  Inserir "Alice saldo=100" e depois "Alice saldo=200" = saldo Ã© 200.

  key=alice, value=100    (t1)
  key=alice, value=200    (t2)
  â†’ KTable vÃª: { alice: 200 } â€” apenas o Ãºltimo valor

  Internamente backed por log compaction.
```

---

### Windowing

```
WINDOWING EM KAFKA STREAMS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  TUMBLING WINDOW (janelas fixas, sem sobreposiÃ§Ã£o)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  |  Window 1  |  Window 2  |  Window 3  |
  | [e1,e2,e3] | [e4,e5]    | [e6,e7,e8] |
  0s          10s          20s          30s

  HOPPING WINDOW (janelas fixas, COM sobreposiÃ§Ã£o)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  |  Window 1 (0-10s)    |
       |  Window 2 (5-15s)    |
            |  Window 3 (10-20s)    |
  size=10s, advance=5s â†’ sobreposiÃ§Ã£o de 5s

  SLIDING WINDOW (janela que desliza com cada evento)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  DiferenÃ§a mÃ¡xima entre timestamps de dois eventos na mesma janela.
  Sem alinhamento com o relÃ³gio â€” definido pela presenÃ§a de eventos.

  SESSION WINDOW (gap-based)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  |e1 e2 e3|    gap > 5min    |e4 e5|    gap > 5min    |e6|
  |session-1|                  |session-2|               |session-3|
  SessÃ£o encerra quando nÃ£o hÃ¡ eventos por inactivityGap.
```

---

### Joins e State Stores

**Joins**: KStream-KStream (windowed, ambos lados sÃ£o eventos), KStream-KTable (enriquecimento â€” join do stream com tabela de referÃªncia), KTable-KTable (join materializado, ambos lados sÃ£o changelogs).

**State stores**: Kafka Streams mantÃ©m estado local usando RocksDB. Para fault tolerance, o state store Ã© backed por um **changelog topic** â€” se o processo cai, o novo consumer reconstrÃ³i o estado a partir do changelog.

**Alternativas**: Apache Flink (processamento stateful distribuÃ­do de grande escala, exatamente-once nativo, SQL support), Spark Streaming (micro-batching, integraÃ§Ã£o com ecossistema Spark). Flink Ã© o padrÃ£o da indÃºstria para stream processing complexo; Kafka Streams Ã© ideal quando o processamento Ã© acoplado a uma aplicaÃ§Ã£o Kafka-centric.

---

## Schema Registry

### Por Que Schemas Importam

Sem schema enforcement, qualquer producer pode publicar qualquer JSON. O consumer descobre que o schema mudou apenas quando quebra em produÃ§Ã£o. Schema Registry resolve isso com contratos formais.

```
SEM SCHEMA REGISTRY:
  Producer v1: { "orderId": "o1", "total": 100 }
  Producer v2: { "order_id": "o1", "amount": 100 }   â† campo renomeado!
  Consumer: JSON.parse(msg).orderId â†’ undefined ğŸ’¥

COM SCHEMA REGISTRY:
  Producer v1: registra schema v1 no Registry
  Producer v2: tenta registrar schema v2 â†’ REJEITADO (breaking change!)
  Consumer: confia que o schema Ã© compatÃ­vel â†’ sem surpresas
```

---

### Avro e Compatibility Modes

```
COMPATIBILITY MODES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  BACKWARD (default):
    Consumer novo pode ler dados escritos pelo producer antigo.
    Pode: adicionar campos com default, remover campos.
    NÃ£o pode: adicionar campos sem default, mudar tipo.

  FORWARD:
    Consumer antigo pode ler dados escritos pelo producer novo.
    Pode: remover campos, adicionar campos com default.
    Oposto do BACKWARD.

  FULL:
    BACKWARD + FORWARD. Ambas as direÃ§Ãµes.
    Mais restritivo. Mais seguro.

  NONE:
    Sem verificaÃ§Ã£o. Qualquer mudanÃ§a aceita.
    âš  Apenas para desenvolvimento.


  AVRO SCHEMA EXAMPLE:
  {
    "type": "record",
    "name": "OrderPlaced",
    "namespace": "com.brewnary.events",
    "fields": [
      { "name": "orderId", "type": "string" },
      { "name": "userId", "type": "string" },
      { "name": "total", "type": "double" },
      { "name": "currency", "type": "string", "default": "BRL" },  â† campo com default (backward-compatible)
      { "name": "occurredAt", "type": "long", "logicalType": "timestamp-millis" }
    ]
  }
```

Alternativa: **Protobuf** com Schema Registry (suporte nativo no Confluent Schema Registry). Protobuf Ã© mais eficiente em tamanho e mais common em ecossistemas gRPC. Avro Ã© mais natural em ecossistemas Kafka/Hadoop.

---

## Event Sourcing

### Conceito: Estado = Replay de Todos os Eventos

Em vez de armazenar o estado atual de uma entidade (linha no banco), **Event Sourcing** armazena a sequÃªncia completa de eventos que levaram ao estado atual. O estado Ã© derivado fazendo replay (fold) dos eventos.

```
TRADITIONAL CRUD                    EVENT SOURCING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  orders table:                     order_events stream:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚order_idâ”‚ status â”‚ total  â”‚      â”‚seqâ”‚   event_type â”‚    data      â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  o1    â”‚shipped â”‚ 250.00 â”‚      â”‚ 1 â”‚OrderCreated  â”‚{total:200}   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ 2 â”‚ItemAdded     â”‚{+50.00}     â”‚
                                    â”‚ 3 â”‚OrderPaid     â”‚{method:pix} â”‚
  VocÃª sabe o estado atual,         â”‚ 4 â”‚OrderShipped  â”‚{tracking:X} â”‚
  mas NÃƒO sabe como chegou lÃ¡.     â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                    Estado atual = fold(eventos)
                                    VocÃª sabe EXATAMENTE como chegou lÃ¡.
                                    Pode reconstruir estado em qualquer ponto no tempo.
```

---

### Event Store, Snapshots e Projections

**Event Store**: banco append-only onde cada stream (aggregate) tem sua sequÃªncia de eventos. Em produÃ§Ã£o: EventStoreDB, ou uma tabela Postgres com constraints de append-only.

**Snapshots**: quando um aggregate tem milhares de eventos, replay fica lento. Um snapshot salva o estado materializado periodicamente. O replay comeÃ§a do snapshot mais recente.

```
SNAPSHOTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Sem snapshot: replay de 10.000 eventos para reconstruir estado â†’ lento
  Com snapshot: snapshot no evento 9.900 + replay dos Ãºltimos 100 â†’ rÃ¡pido

  [e1] [e2] ... [e9900] [SNAPSHOT] [e9901] ... [e10000]
                             â–²
                             â”‚
                   Estado materializado atÃ© aqui.
                   Replay comeÃ§a daqui.
```

**Projections**: materializam read models a partir do event stream. SÃ£o consumers que leem eventos e escrevem em tabelas denormalizadas, otimizadas para queries especÃ­ficas.

---

### ImplementaÃ§Ã£o PrÃ¡tica: Event Sourcing em TypeScript

```typescript
// event-sourcing.ts â€” ImplementaÃ§Ã£o simplificada de Event Sourcing

// â”€â”€â”€ DOMAIN EVENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
type OrderEvent =
  | { type: 'OrderCreated'; orderId: string; userId: string; createdAt: string }
  | { type: 'ItemAdded'; orderId: string; productId: string; quantity: number; price: number }
  | { type: 'ItemRemoved'; orderId: string; productId: string }
  | { type: 'OrderPaid'; orderId: string; method: string; paidAt: string }
  | { type: 'OrderShipped'; orderId: string; trackingCode: string; shippedAt: string }
  | { type: 'OrderCancelled'; orderId: string; reason: string; cancelledAt: string };

// â”€â”€â”€ AGGREGATE STATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
interface OrderState {
  orderId: string;
  userId: string;
  status: 'created' | 'paid' | 'shipped' | 'cancelled';
  items: Map<string, { quantity: number; price: number }>;
  total: number;
  version: number;
}

function initialState(): OrderState {
  return {
    orderId: '',
    userId: '',
    status: 'created',
    items: new Map(),
    total: 0,
    version: 0,
  };
}

// â”€â”€â”€ REDUCER (evolve) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// FunÃ§Ã£o pura: dado um estado e um evento, retorna o novo estado.
// Sem side effects. Sem I/O. TestÃ¡vel trivialmente.
function evolve(state: OrderState, event: OrderEvent): OrderState {
  switch (event.type) {
    case 'OrderCreated':
      return { ...state, orderId: event.orderId, userId: event.userId, status: 'created', version: state.version + 1 };

    case 'ItemAdded': {
      const items = new Map(state.items);
      items.set(event.productId, { quantity: event.quantity, price: event.price });
      const total = [...items.values()].reduce((sum, item) => sum + item.quantity * item.price, 0);
      return { ...state, items, total, version: state.version + 1 };
    }

    case 'ItemRemoved': {
      const items = new Map(state.items);
      items.delete(event.productId);
      const total = [...items.values()].reduce((sum, item) => sum + item.quantity * item.price, 0);
      return { ...state, items, total, version: state.version + 1 };
    }

    case 'OrderPaid':
      return { ...state, status: 'paid', version: state.version + 1 };

    case 'OrderShipped':
      return { ...state, status: 'shipped', version: state.version + 1 };

    case 'OrderCancelled':
      return { ...state, status: 'cancelled', version: state.version + 1 };
  }
}

// â”€â”€â”€ REBUILD STATE FROM EVENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function rebuildState(events: OrderEvent[]): OrderState {
  return events.reduce(evolve, initialState());
}

// â”€â”€â”€ COMMAND HANDLERS (com validaÃ§Ã£o) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Commands validam regras de negÃ³cio ANTES de emitir eventos.
function addItem(
  state: OrderState,
  productId: string,
  quantity: number,
  price: number
): OrderEvent {
  if (state.status !== 'created') {
    throw new Error(`Cannot add items to order in status: ${state.status}`);
  }
  if (quantity <= 0 || price <= 0) {
    throw new Error('Quantity and price must be positive');
  }
  return {
    type: 'ItemAdded',
    orderId: state.orderId,
    productId,
    quantity,
    price,
  };
}

function payOrder(state: OrderState, method: string): OrderEvent {
  if (state.status !== 'created') {
    throw new Error(`Cannot pay order in status: ${state.status}`);
  }
  if (state.items.size === 0) {
    throw new Error('Cannot pay for an empty order');
  }
  return {
    type: 'OrderPaid',
    orderId: state.orderId,
    method,
    paidAt: new Date().toISOString(),
  };
}

// â”€â”€â”€ USAGE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const events: OrderEvent[] = [
  { type: 'OrderCreated', orderId: 'o1', userId: 'u1', createdAt: '2025-01-15T10:00:00Z' },
  { type: 'ItemAdded', orderId: 'o1', productId: 'p1', quantity: 2, price: 50.00 },
  { type: 'ItemAdded', orderId: 'o1', productId: 'p2', quantity: 1, price: 150.00 },
  { type: 'OrderPaid', orderId: 'o1', method: 'pix', paidAt: '2025-01-15T10:05:00Z' },
  { type: 'OrderShipped', orderId: 'o1', trackingCode: 'BR123456789', shippedAt: '2025-01-16T08:00:00Z' },
];

const currentState = rebuildState(events);
// â†’ { orderId: 'o1', status: 'shipped', total: 250.00, items: Map(2), version: 5 }

// Time-travel: reconstruir estado em qualquer ponto
const stateAfterPayment = rebuildState(events.slice(0, 4));
// â†’ { orderId: 'o1', status: 'paid', total: 250.00, version: 4 }
```

### Quando Usar e Quando NAO Usar Event Sourcing

```
USE EVENT SOURCING QUANDO:
  âœ“ Auditoria completa Ã© requisito regulatÃ³rio (financeiro, saÃºde)
  âœ“ Precisa de time-travel debugging ou replay
  âœ“ DomÃ­nio Ã© naturalmente event-driven (pedidos, transaÃ§Ãµes, workflows)
  âœ“ Precisa projetar mÃºltiplas read views a partir dos mesmos dados
  âœ“ Equipe tem maturidade para lidar com eventual consistency

NÃƒO USE EVENT SOURCING QUANDO:
  âœ— CRUD simples resolve o problema (cadastro de usuÃ¡rios, configuraÃ§Ãµes)
  âœ— Equipe nÃ£o tem experiÃªncia com sistemas distribuÃ­dos
  âœ— Requisitos de consistÃªncia forte (read-your-writes obrigatÃ³rio)
  âœ— Volume de eventos por aggregate Ã© muito baixo (overhead nÃ£o compensa)
  âœ— NÃ£o hÃ¡ necessidade real de auditoria ou replay
```

---

## CQRS (Command Query Responsibility Segregation)

### SeparaÃ§Ã£o de Write Model e Read Model

CQRS separa a aplicaÃ§Ã£o em dois lados: o **write side** (recebe comandos, aplica domain logic, gera eventos) e o **read side** (materializa views otimizadas para queries, eventualmente consistentes).

```
CQRS + EVENT SOURCING â€” ARQUITETURA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                      WRITE SIDE                    READ SIDE
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   PlaceOrder â”€â”€â”€â”€â”€â–ºâ”‚  Command      â”‚             â”‚  Query        â”‚â—„â”€â”€ GetOrderById
   AddItem â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Handler      â”‚             â”‚  Handler      â”‚â—„â”€â”€ ListOrdersByUser
   PayOrder â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚               â”‚             â”‚               â”‚â—„â”€â”€ GetOrderStats
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                              â–²
                           â”‚ validate                     â”‚ read
                           â”‚ + emit events                â”‚
                           â–¼                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Event Store  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Read DB      â”‚
                    â”‚  (append-only)â”‚  projections â”‚  (Postgres,   â”‚
                    â”‚               â”‚  (consumers) â”‚  Elasticsearchâ”‚
                    â”‚  Kafka /      â”‚             â”‚  Redis, etc.) â”‚
                    â”‚  EventStoreDB â”‚             â”‚               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Write path: Command â†’ Validate â†’ Event(s) â†’ Event Store â†’ ACK
  Read path:  Query â†’ Read DB â†’ Response (denormalized, fast)

  Eventual consistency: write events sÃ£o projetados para o read DB
  de forma assÃ­ncrona. Lag tÃ­pico: milliseconds a segundos.
```

---

### Write Side vs Read Side

**Write side**: contÃ©m toda a domain logic. Valida invariantes de negÃ³cio. Gera eventos. O model Ã© otimizado para proteger regras (aggregates, entities, value objects). Pode ser complexo (DDD).

**Read side**: zero domain logic. Tabelas denormalizadas, otimizadas para queries especÃ­ficas. Pode ter mÃºltiplas projeÃ§Ãµes para diferentes use cases (ex: uma view para o admin, outra para analytics, outra para o dashboard do usuÃ¡rio). Cada projeÃ§Ã£o Ã© um consumer group independente.

```
EXEMPLO: ORDER READ MODELS (mÃºltiplas projeÃ§Ãµes)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Event Stream: [OrderCreated, ItemAdded, ItemAdded, OrderPaid, OrderShipped]

  ProjeÃ§Ã£o 1 â€” "order_details" (para API do cliente):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚order_idâ”‚user_id â”‚ total  â”‚  status  â”‚ tracking_code â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚  o1    â”‚  u1    â”‚ 250.00 â”‚ shipped  â”‚ BR123456789   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  ProjeÃ§Ã£o 2 â€” "daily_revenue" (para dashboard analytics):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    date    â”‚ total_rev â”‚ num_ordersâ”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ 2025-01-15 â”‚  12500.00 â”‚    47    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  ProjeÃ§Ã£o 3 â€” "user_order_history" (para Elasticsearch, full-text search):
  Documento JSON indexado com items, status, datas â€” search-optimized.
```

---

### Quando CQRS Vale a Pena

```
CQRS VALE A PENA QUANDO:
  âœ“ Read e write patterns sÃ£o MUITO diferentes
    (ex: writes complexos com validaÃ§Ã£o, reads simples mas de alto volume)
  âœ“ Read side precisa de mÃºltiplas representaÃ§Ãµes (SQL, Elasticsearch, cache)
  âœ“ Escala de leitura >> escala de escrita (escala cada lado independentemente)
  âœ“ Combinado com Event Sourcing (projeÃ§Ãµes sÃ£o o read model natural)
  âœ“ Domain logic Ã© complexa (DDD com aggregates grandes)

CQRS Ã‰ OVERHEAD DESNECESSÃRIO QUANDO:
  âœ— CRUD simples (read e write models sÃ£o idÃªnticos)
  âœ— Poucos usuÃ¡rios, baixo volume (over-engineering)
  âœ— Equipe pequena sem experiÃªncia em sistemas distribuÃ­dos
  âœ— Requisito de strong consistency imediata (sem tolerance para eventual consistency)
  âœ— Um Ãºnico banco relacional atende todas as queries eficientemente
```

---

## Outbox Pattern

### O Problema: Dual-Write

O problema mais traiÃ§oeiro de sistemas event-driven: vocÃª precisa salvar no banco **E** publicar um evento. Se fizer os dois separadamente, pode ficar inconsistente.

```
DUAL-WRITE PROBLEM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  CenÃ¡rio 1 â€” Banco primeiro, depois Kafka:
    1. BEGIN transaction
    2. INSERT INTO orders (...)              âœ“ sucesso
    3. COMMIT                                âœ“ sucesso
    4. kafka.publish("OrderPlaced", {...})   âœ— Kafka fora do ar!
    â†’ Dado salvo no banco, MAS evento nunca publicado.
    â†’ Consumers nunca ficam sabendo. Sistema inconsistente.

  CenÃ¡rio 2 â€” Kafka primeiro, depois banco:
    1. kafka.publish("OrderPlaced", {...})   âœ“ sucesso
    2. BEGIN transaction
    3. INSERT INTO orders (...)              âœ— constraint violation!
    â†’ Evento publicado, MAS dado nÃ£o salvo.
    â†’ Consumers processam evento fantasma.

  CenÃ¡rio 3 â€” Ambos dentro de "transaÃ§Ã£o":
    Kafka NÃƒO participa de transaÃ§Ãµes distribuÃ­das (XA/2PC).
    NÃ£o existe transaÃ§Ã£o atÃ´mica entre Postgres e Kafka.
```

---

### SoluÃ§Ã£o: Transactional Outbox

A soluÃ§Ã£o Ã© escrever o evento em uma **tabela outbox** dentro da **mesma transaÃ§Ã£o** do banco. Um processo separado (CDC ou polling) lÃª a outbox e publica no Kafka.

```
OUTBOX PATTERN â€” FLUXO COMPLETO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                     APPLICATION                         â”‚
  â”‚                                                         â”‚
  â”‚  1. BEGIN TRANSACTION                                   â”‚
  â”‚  2. INSERT INTO orders (...) VALUES (...)               â”‚
  â”‚  3. INSERT INTO outbox (aggregate_type, aggregate_id,   â”‚
  â”‚                         event_type, payload)            â”‚
  â”‚  4. COMMIT                                              â”‚
  â”‚                                                         â”‚
  â”‚  âœ“ Ambas as escritas na MESMA transaÃ§Ã£o ACID            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                     DATABASE                            â”‚
  â”‚                                                         â”‚
  â”‚  orders table:     outbox table:                        â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â” â”‚
  â”‚  â”‚ id   â”‚ ... â”‚   â”‚ id â”‚event_type â”‚ payload  â”‚ sent â”‚ â”‚
  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤ â”‚
  â”‚  â”‚ o1   â”‚ ... â”‚   â”‚  1 â”‚OrderPlacedâ”‚ {...}    â”‚ falseâ”‚ â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜ â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚              CDC (Debezium) ou Polling                   â”‚
  â”‚                                                         â”‚
  â”‚  Debezium: lÃª WAL do Postgres (logical replication)     â”‚
  â”‚  Polling: SELECT * FROM outbox WHERE sent = false       â”‚
  â”‚                                                         â”‚
  â”‚  Publica evento no Kafka, marca como enviado.           â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    KAFKA    â”‚
                        â”‚  topic:     â”‚
                        â”‚  "orders"   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### CDC com Debezium

**Debezium** Ã© um conector CDC (Change Data Capture) que lÃª o WAL (Write-Ahead Log) do banco de dados e publica as mudanÃ§as como eventos no Kafka. NÃ£o precisa de polling â€” Ã© push-based via logical replication.

```
DEBEZIUM â€” COMO FUNCIONA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Postgres (WAL) â”€â”€logical replicationâ”€â”€â–º Debezium Connector â”€â”€â–º Kafka

  1. App faz INSERT na tabela outbox (dentro da transaÃ§Ã£o)
  2. Postgres escreve no WAL (Write-Ahead Log)
  3. Debezium lÃª o WAL via logical replication slot
  4. Transforma a row change em um evento Kafka
  5. Publica no topic configurado

  Vantagens vs Polling:
  â€¢ Sem queries repetitivas no banco (zero impacto em produÃ§Ã£o)
  â€¢ LatÃªncia sub-segundo (lÃª WAL em near real-time)
  â€¢ NÃ£o perde eventos (WAL Ã© a fonte de verdade)
  â€¢ Detecta DELETE, UPDATE, INSERT automaticamente
```

---

### ImplementaÃ§Ã£o PrÃ¡tica do Outbox Pattern

```typescript
// outbox-pattern.ts â€” ImplementaÃ§Ã£o com Prisma + Postgres

import { PrismaClient } from '@prisma/client';

const prisma = new PrismaClient();

interface OutboxEvent {
  aggregateType: string;
  aggregateId: string;
  eventType: string;
  payload: Record<string, unknown>;
}

// â”€â”€â”€ WRITE SIDE: Salvar dado + outbox na mesma transaÃ§Ã£o â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function placeOrder(
  userId: string,
  items: Array<{ productId: string; quantity: number; price: number }>
): Promise<string> {
  const orderId = crypto.randomUUID();
  const total = items.reduce((sum, item) => sum + item.quantity * item.price, 0);

  // TransaÃ§Ã£o ACID: ambas as operaÃ§Ãµes sÃ£o atÃ´micas
  await prisma.$transaction(async (tx) => {
    // 1. Salva o pedido
    await tx.order.create({
      data: {
        id: orderId,
        userId,
        status: 'CREATED',
        total,
        items: { create: items },
      },
    });

    // 2. Salva o evento na outbox (mesma transaÃ§Ã£o!)
    await tx.outboxEvent.create({
      data: {
        id: crypto.randomUUID(),
        aggregateType: 'Order',
        aggregateId: orderId,
        eventType: 'OrderPlaced',
        payload: {
          orderId,
          userId,
          items,
          total,
          occurredAt: new Date().toISOString(),
        },
        createdAt: new Date(),
      },
    });
  });

  return orderId;
}

// â”€â”€â”€ POLLING PUBLISHER (alternativa simples ao Debezium) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Roda como um background job (cron, setInterval, ou worker dedicado)
import { Kafka } from 'kafkajs';

const kafka = new Kafka({ clientId: 'outbox-publisher', brokers: ['kafka:9092'] });
const producer = kafka.producer({ idempotent: true });

async function publishOutboxEvents(): Promise<void> {
  // Busca eventos nÃ£o publicados, ordenados por criaÃ§Ã£o
  const events = await prisma.outboxEvent.findMany({
    where: { publishedAt: null },
    orderBy: { createdAt: 'asc' },
    take: 100, // batch size
  });

  if (events.length === 0) return;

  for (const event of events) {
    try {
      await producer.send({
        topic: `${event.aggregateType.toLowerCase()}.events`,
        messages: [{
          key: event.aggregateId,
          value: JSON.stringify(event.payload),
          headers: {
            'event-type': event.eventType,
            'aggregate-type': event.aggregateType,
            'event-id': event.id,
          },
        }],
      });

      // Marca como publicado
      await prisma.outboxEvent.update({
        where: { id: event.id },
        data: { publishedAt: new Date() },
      });
    } catch (error) {
      console.error(`Failed to publish event ${event.id}:`, error);
      break; // para de publicar para manter ordem
    }
  }
}

// Executa a cada 1 segundo
setInterval(publishOutboxEvents, 1000);

// â”€â”€â”€ SQL: Schema da tabela outbox â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
/*
CREATE TABLE outbox_events (
  id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  aggregate_type  VARCHAR(100) NOT NULL,
  aggregate_id    VARCHAR(100) NOT NULL,
  event_type      VARCHAR(100) NOT NULL,
  payload         JSONB NOT NULL,
  created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  published_at    TIMESTAMPTZ NULL,

  -- Index para o polling publisher
  -- Partial index: sÃ³ eventos nÃ£o publicados
  CREATE INDEX idx_outbox_unpublished ON outbox_events (created_at)
    WHERE published_at IS NULL;
);
*/
```

---

## Comparacao: Kafka vs RabbitMQ vs SQS vs NATS vs Pulsar

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â”‚   KAFKA    â”‚  RABBITMQ  â”‚  AWS SQS   â”‚    NATS    â”‚   PULSAR   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model            â”‚ Log        â”‚ Queue      â”‚ Queue      â”‚ Pub/Sub    â”‚ Log+Queue  â”‚
â”‚                  â”‚ (commit    â”‚ (AMQP      â”‚ (managed   â”‚ (cloud-    â”‚ (unificado)â”‚
â”‚                  â”‚  log)      â”‚  broker)   â”‚  queue)    â”‚  native)   â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ordering         â”‚ Per-       â”‚ Per-queue  â”‚ Best-      â”‚ Nenhuma    â”‚ Per-       â”‚
â”‚                  â”‚ partition  â”‚ (FIFO)     â”‚ effort     â”‚ (JetStream:â”‚ partition  â”‚
â”‚                  â”‚            â”‚            â”‚ (FIFO opt.)â”‚ per-stream)â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Delivery         â”‚ At-least-  â”‚ At-least-  â”‚ At-least-  â”‚ At-most-   â”‚ At-least-  â”‚
â”‚ Semantics        â”‚ once       â”‚ once       â”‚ once       â”‚ once       â”‚ once       â”‚
â”‚                  â”‚ (exactly-  â”‚ (com ACK   â”‚            â”‚ (JetStream:â”‚ (exactly-  â”‚
â”‚                  â”‚  once c/   â”‚  manual)   â”‚            â”‚ at-least-  â”‚  once c/   â”‚
â”‚                  â”‚  tx API)   â”‚            â”‚            â”‚ once)      â”‚  tx API)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Throughput       â”‚ MilhÃµes    â”‚ ~50K       â”‚ ~3K (SQS   â”‚ MilhÃµes    â”‚ MilhÃµes    â”‚
â”‚                  â”‚ msg/s      â”‚ msg/s      â”‚ Standard)  â”‚ msg/s      â”‚ msg/s      â”‚
â”‚                  â”‚            â”‚            â”‚ ~300 (FIFO)â”‚            â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Latency (p99)    â”‚ ~5-15ms    â”‚ ~1-5ms     â”‚ ~20-50ms   â”‚ <1ms       â”‚ ~5-10ms    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Retention        â”‚ ConfigurÃ¡- â”‚ AtÃ©        â”‚ 14 dias    â”‚ JetStream: â”‚ ConfigurÃ¡- â”‚
â”‚                  â”‚ vel (dias, â”‚ consumo    â”‚ max        â”‚ configurÃ¡- â”‚ vel        â”‚
â”‚                  â”‚ infinito)  â”‚ (TTL opt.) â”‚            â”‚ vel        â”‚ (tiered    â”‚
â”‚                  â”‚            â”‚            â”‚            â”‚            â”‚  storage)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Replay           â”‚ âœ“ (reset   â”‚ âœ—          â”‚ âœ—          â”‚ âœ“ (Jet-    â”‚ âœ“          â”‚
â”‚                  â”‚  offset)   â”‚            â”‚            â”‚  Stream)   â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Use Cases        â”‚ Event      â”‚ Task       â”‚ Serverless â”‚ Microser-  â”‚ Multi-     â”‚
â”‚ Ideais           â”‚ streaming, â”‚ queues,    â”‚ decoupling,â”‚ vices      â”‚ tenant,    â”‚
â”‚                  â”‚ CDC, log   â”‚ RPC async, â”‚ AWS-native â”‚ comms,     â”‚ geo-repli- â”‚
â”‚                  â”‚ aggregationâ”‚ routing    â”‚ workloads  â”‚ IoT, edge  â”‚ cation,    â”‚
â”‚                  â”‚ analytics  â”‚ complexo   â”‚            â”‚            â”‚ Kafka      â”‚
â”‚                  â”‚            â”‚            â”‚            â”‚            â”‚ migration  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Operacional      â”‚ Alto       â”‚ MÃ©dio      â”‚ Zero       â”‚ Baixo      â”‚ Alto       â”‚
â”‚ Complexity       â”‚ (ou use    â”‚            â”‚ (managed)  â”‚            â”‚ (ou use    â”‚
â”‚                  â”‚ Confluent) â”‚            â”‚            â”‚            â”‚ StreamNat.)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Regra prÃ¡tica**: Kafka quando precisa de event streaming, replay, CDC e retenÃ§Ã£o. RabbitMQ quando precisa de roteamento flexÃ­vel e task distribution. SQS quando jÃ¡ estÃ¡ na AWS e precisa de zero ops. NATS quando precisa de latÃªncia ultra-baixa e simplicidade. Pulsar quando precisa de multi-tenancy e tiered storage nativos.

---

## Kafka em Producao

### Partition Strategy

O nÃºmero de partitions determina o paralelismo mÃ¡ximo de consumers. Escolher errado causa problemas difÃ­ceis de resolver depois (reparticionamento requer migraÃ§Ã£o).

```
COMO ESCOLHER O NÃšMERO DE PARTITIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  FÃ³rmula base:
    numPartitions â‰¥ max(throughput_desejado / throughput_por_consumer,
                        throughput_desejado / throughput_por_producer)

  Exemplo:
    Target: 100K msg/s
    Cada consumer processa: 10K msg/s
    â†’ MÃ­nimo 10 partitions (10 consumers paralelos)

  Regras prÃ¡ticas:
  â€¢ Comece com 6-12 partitions para topics de alto volume
  â€¢ 3-6 para topics de volume moderado
  â€¢ Mais partitions = mais file handles, mais memÃ³ria, rebalance mais lento
  â€¢ Nunca reduza partitions depois (sÃ³ aumentar)
  â€¢ Partition count excessivo: overhead de metadata, leader election mais lento
  â€¢ max.message.bytes vs message.max.bytes: limites por partition e por broker
```

---

### Monitoring

```
MÃ‰TRICAS CRÃTICAS PARA MONITORAR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  CONSUMER LAG (a mais importante):
    DiferenÃ§a entre o latest offset e o committed offset do consumer.
    Lag crescente = consumer nÃ£o estÃ¡ acompanhando produÃ§Ã£o.
    Alerta: lag > threshold por > 5 minutos.

  UNDER-REPLICATED PARTITIONS:
    Partitions onde alguma rÃ©plica nÃ£o estÃ¡ no ISR.
    > 0 = risco de perda de dados se o leader cair.
    Alerta: qualquer valor > 0.

  ISR SHRINK/EXPAND RATE:
    FrequÃªncia com que rÃ©plicas saem/entram do ISR.
    Alta taxa = brokers instÃ¡veis, rede saturada, disco lento.

  REQUEST LATENCY (produce/fetch):
    LatÃªncia do broker para processar requests.
    p99 > 100ms = investigar.

  DISK USAGE:
    Retention policies + throughput = consumo de disco previsÃ­vel.
    Alerta: > 80% de uso.

  Ferramentas:
  â€¢ Conduktor: UI comercial, excelente para dev/staging
  â€¢ AKHQ (open-source): visualizaÃ§Ã£o de topics, consumers, schemas
  â€¢ Kafka UI (Provectus): open-source, leve, boa UX
  â€¢ Burrow (LinkedIn): monitoring especializado de consumer lag
  â€¢ Prometheus + Grafana: JMX metrics via JMX Exporter
```

---

### MirrorMaker 2: Cross-Datacenter Replication

MirrorMaker 2 (MM2) replica topics entre clusters Kafka em diferentes datacenters. Baseado em Kafka Connect, suporta active-active e active-passive.

```
MIRRORMAKER 2 â€” CROSS-DATACENTER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Cluster DC-1     â”‚           â”‚  Cluster DC-2     â”‚
  â”‚  (primary)        â”‚           â”‚  (secondary)      â”‚
  â”‚                   â”‚           â”‚                   â”‚
  â”‚  topic: orders    â”‚â”€â”€MM2â”€â”€â”€â”€â–ºâ”‚  topic: dc1.ordersâ”‚
  â”‚  topic: payments  â”‚â”€â”€MM2â”€â”€â”€â”€â–ºâ”‚  topic: dc1.paymentsâ”‚
  â”‚                   â”‚           â”‚                   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â€¢ Topics replicados com prefixo do cluster de origem
  â€¢ Offset translation: mantÃ©m mapeamento de offsets entre clusters
  â€¢ Heartbeats e checkpoints para monitorar replication lag
  â€¢ Active-active: ambos clusters produzem e consomem, MM2 replica bidirecionalmente
```

---

## Exercicios Praticos

### Exercicio 1 â€” Producer com Garantias

Implemente um producer KafkaJS que publique eventos `UserRegistered` com as seguintes configuraÃ§Ãµes: `idempotent: true`, `acks: -1`, compression LZ4, key = userId. O producer deve fazer batching de atÃ© 100 mensagens antes de enviar. Adicione headers com `event-type`, `schema-version` e `correlation-id`. Teste publicando 10.000 eventos e verifique que nÃ£o hÃ¡ duplicatas no topic (use `kafka-console-consumer` com `--from-beginning`).

### Exercicio 2 â€” Consumer Resiliente com DLQ

Implemente um consumer que processe eventos `OrderPlaced` com manual commit. O consumer deve: (1) verificar idempotÃªncia usando um Set ou Redis, (2) retry atÃ© 3 vezes com backoff exponencial em caso de falha, (3) enviar para um topic DLQ (`orders.dlq`) apÃ³s esgotar retries. Simule falhas aleatÃ³rias (Math.random() < 0.3) no handler para validar o fluxo de retry + DLQ.

### Exercicio 3 â€” Event Sourcing: Conta BancÃ¡ria

Implemente um sistema de Event Sourcing para uma conta bancÃ¡ria com os eventos: `AccountOpened`, `MoneyDeposited`, `MoneyWithdrawn`, `AccountClosed`. Implemente: (1) a funÃ§Ã£o `evolve` (reducer) que reconstrÃ³i o estado, (2) command handlers com validaÃ§Ã£o (ex: saldo insuficiente para saque, conta fechada nÃ£o aceita depÃ³sitos), (3) uma funÃ§Ã£o de snapshot que salva o estado a cada 100 eventos. Escreva testes unitÃ¡rios para o reducer â€” ele Ã© puro, portanto trivialmente testÃ¡vel.

### Exercicio 4 â€” Outbox Pattern com Polling

Implemente o Outbox Pattern usando Prisma + Postgres: (1) crie a migration com a tabela `outbox_events`, (2) implemente a funÃ§Ã£o de negÃ³cio que salva na tabela principal + outbox na mesma transaÃ§Ã£o, (3) implemente o polling publisher que lÃª eventos nÃ£o publicados e envia para Kafka. Garanta idempotÃªncia no publisher usando o `event-id` como header e verificando duplicatas no consumer.

### Exercicio 5 â€” CQRS: Read Models

Usando os eventos do Exercicio 3 (conta bancÃ¡ria), implemente dois read models: (1) `account_balances` â€” tabela com saldo atual de cada conta (projeÃ§Ã£o simples), (2) `monthly_statements` â€” tabela com extrato mensal agregado (total de depositos, total de saques, saldo final por mes). Implemente os projectors como consumers Kafka que materializam essas views em Postgres.

### Exercicio 6 â€” Monitoring de Consumer Lag

Configure um ambiente local com Docker Compose (Kafka + ZooKeeper ou KRaft) e Kafka UI. Crie um producer que publique 1.000 msg/s e um consumer que processe 500 msg/s (simule com `setTimeout`). Monitore o consumer lag crescendo no Kafka UI. Escale para 2 consumers e observe o lag diminuir. Experimente matar um consumer e observe o rebalancing.

---

## Referencias

- **"Designing Event-Driven Systems"** â€” Ben Stopford (Confluent, gratuito). Melhor introduÃ§Ã£o a event-driven com Kafka. Cobre event sourcing, CQRS, e patterns de streaming.
- **"Kafka: The Definitive Guide"** â€” Neha Narkhede, Gwen Shapira, Todd Palino (O'Reilly). ReferÃªncia completa sobre Kafka internals, operaÃ§Ãµes e best practices.
- **"Building Event-Driven Microservices"** â€” Adam Bellemare (O'Reilly). Foco em microserviÃ§os event-driven com Kafka.
- **Martin Fowler â€” Event Sourcing**: https://martinfowler.com/eaaDev/EventSourcing.html
- **Martin Fowler â€” CQRS**: https://martinfowler.com/bliki/CQRS.html
- **Confluent Documentation**: https://docs.confluent.io/ â€” referÃªncia oficial, excelente cobertura de Kafka Streams, Schema Registry e Connect.
- **KafkaJS Documentation**: https://kafka.js.org/ â€” client Node.js/TypeScript para Kafka.
- **Debezium Documentation**: https://debezium.io/documentation/ â€” CDC com Kafka Connect.
- **KIP-500 (KRaft)**: https://cwiki.apache.org/confluence/display/KAFKA/KIP-500 â€” remoÃ§Ã£o do ZooKeeper.
